{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2183072b",
      "metadata": {},
      "source": [
        "%md\n",
        "\n",
        "# Fenêtres temporelles\n",
        "\n",
        "* On utilise les fenêtres glissantes pour agréger des morceaux de données plutôt que toutes les données (par exemple, toutes les 5 minutes ou toutes les heures)\n",
        "* On applique le watermarking pour jeter les anciennes données obsolètes que vous n'avez pas l'espace de conserver\n",
        "* `display` permet de tracez des graphiques en direct (sur databricks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c68510f",
      "metadata": {},
      "source": [
        "%md\n",
        "\n",
        "<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Agrégations en Streaming</h2>\n",
        "\n",
        "Les applications continues nécessitent souvent des décisions quasi en temps réel sur des statistiques agrégées en temps réel.\n",
        "\n",
        "Quelques exemples incluent\n",
        "* Agréger les erreurs dans les données des dispositifs IoT par type\n",
        "* Détecter un comportement anormal dans le fichier journal d'un serveur en agrégeant par pays\n",
        "* Faire une analyse de comportement sur les messages instantanés via des hashtags.\n",
        "\n",
        "Cependant, dans le cas des flux, vous ne voulez généralement pas exécuter des agrégations sur l'ensemble du jeu de données.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d860cb",
      "metadata": {},
      "source": [
        "%md\n",
        "Exemple agrégations en Streaming\n",
        "\n",
        "Fichers à examiner : `/mnt/training/sensor-data/accelerometer/time-series-stream.json/`.\n",
        "\n",
        "Chaque ligne du fichier contient un enregistrement JSON avec deux champs : `time` et `action`\n",
        "\n",
        "De nouveaux fichiers sont continuellement écrits dans ce répertoire (en streaming).\n",
        "\n",
        "Théoriquement, ce processus n'a pas de fin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e03b153e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from delta import configure_spark_with_delta_pip\n",
        "from pyspark.sql.functions import col, from_json, to_timestamp\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
        "\n",
        "# Netoyage des variables d'env qui peuvent casser le bind du driver\n",
        "for var in [\"SPARK_LOCAL_IP\", \"SPARK_DRIVER_BIND_ADDRESS\", \"SPARK_DRIVER_HOST\"]:\n",
        "    os.environ.pop(var, None)\n",
        "\n",
        "# Packages Kafka pour Spark (adapter la version si ton pyspark n'est pas 3.5.*)\n",
        "EXTRA_PACKAGES = [\n",
        "    \"org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.2\",\n",
        "]\n",
        "\n",
        "builder = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"SmartTech-Streaming-Silver\")\n",
        "    .master(\"local[*]\")\n",
        "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
        "    .config(\"spark.driver.host\", \"localhost\")\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        ")\n",
        "\n",
        "# on passe Kafka via extra_packages\n",
        "spark = configure_spark_with_delta_pip(builder, extra_packages=EXTRA_PACKAGES).getOrCreate()\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9cd8fa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Définir le schéma pour le contenu en streaming\n",
        "inputPath = \"/.../veille/stream_events\"\n",
        "jsonSchema = \"time timestamp, action string\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81e0e90",
      "metadata": {},
      "source": [
        "%md\n",
        "\n",
        "Définir un DataFrame de streaming initial `inputDf` puis `countsDF` qui représente une agrégation \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "19a4ea96",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import window, col\n",
        "\n",
        "inputDF = (spark\n",
        "  .readStream                                 \n",
        "  .schema(jsonSchema)                         \n",
        "  .option(\"maxFilesPerTrigger\", 1)            \n",
        "  .json(inputPath)                           \n",
        ")\n",
        "\n",
        "countsDF = (inputDF\n",
        "  .groupBy(col(\"action\"),                     # agrège les données par action\n",
        "           window(col(\"time\"), \"1 hour\"))     # puis par des fenêtres temporelles d'une heure\n",
        "  .count()                                    # produit un décompte pour chaque agrégation\n",
        "  .select(col(\"window.start\").alias(\"start\"), # Transforme le champ en une colonne\n",
        "          col(\"action\"),                      # Inclut l'action\n",
        "          col(\"count\"))                       # Inclut le décompte\n",
        "  .orderBy(col(\"start\"), col(\"action\"))       # Trie par heure de début et par action\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1d52ff",
      "metadata": {},
      "source": [
        "%md\n",
        "\n",
        "Résultats requête\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a42af886",
      "metadata": {},
      "outputs": [],
      "source": [
        "#spark.conf.set(\"spark.sql.shuffle.partitions\", sc.defaultParallelism)\n",
        "\n",
        "#display(countsDF)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c30441b",
      "metadata": {},
      "source": [
        "# Problème avec la génération de nombreuses fenêtres (Structured Streaming)\n",
        "\n",
        "Quand on fait une agrégation fenêtrée en Structured Streaming (par exemple `window(time, \"1 hour\")` + `count()`), Spark doit **maintenir un état (state)** pour **chaque fenêtre** tant qu’il considère que de nouveaux événements peuvent encore arriver pour cette fenêtre.\n",
        "\n",
        "## Pourquoi ça peut devenir un problème ?\n",
        "- Chaque fenêtre (ou chaque combinaison de clés + fenêtre) correspond à une portion d’état à conserver.\n",
        "- **Sans limite temporelle**, Spark doit supposer que des données *en retard* (late data) peuvent arriver indéfiniment pour des fenêtres passées.\n",
        "- Résultat : le nombre de fenêtres conservées **augmente sans limite**, l’état grossit et on peut observer :\n",
        "  - ralentissements importants,\n",
        "  - consommation mémoire élevée côté **executors** (state store),\n",
        "  - voire des erreurs de type **Out Of Memory**.\n",
        "\n",
        "> Remarque : l’état est principalement stocké dans le *state store* sur les executors (pas “dans le driver”), même si le driver coordonne l’exécution.\n",
        "\n",
        "---\n",
        "\n",
        "## Solutions possibles\n",
        "\n",
        "### 1) Augmenter la taille des fenêtres (ex: 4 heures)\n",
        "Augmenter la durée de la fenêtre peut réduire le **nombre** de fenêtres actives à gérer à un instant donné.\n",
        "\n",
        "Avantage : moins de fenêtres simultanées.  \n",
        "Limite : si le job tourne longtemps, on accumule quand même un historique potentiellement illimité → l’état continue à croître.\n",
        "\n",
        "---\n",
        "\n",
        "### 2) Utiliser un watermark (solution recommandée)\n",
        "Le **watermark** permet de définir une **limite de retard acceptable** sur la colonne de temps d’événement.\n",
        "\n",
        "Exemple :\n",
        "```python\n",
        "df = (df\n",
        "  .withWatermark(\"time\", \"10 minutes\")\n",
        "  .groupBy(window(col(\"time\"), \"1 hour\"))\n",
        "  .count()\n",
        ")\n",
        "```\n",
        "\n",
        "#### Que dit le watermark à Spark ?\n",
        "> “Je n’attends pas d’événements plus anciens que *max(event_time) - 10 minutes*.”\n",
        "\n",
        "#### Effets concrets\n",
        "- Spark peut **finaliser** les fenêtres trop anciennes (au-delà du watermark).\n",
        "- L’état associé à ces fenêtres peut être **nettoyé / supprimé**.\n",
        "- Les événements arrivant **après** la limite (trop en retard) peuvent être ignorés (selon le mode de sortie).\n",
        "\n",
        "Avantage : l’état devient **borné dans le temps**, ce qui stabilise l’utilisation mémoire et améliore la robustesse des agrégations fenêtrées sur de longues durées.\n",
        "\n",
        "---\n",
        "\n",
        "## À retenir\n",
        "- Le watermark sert d’abord à **gérer la donnée en retard** et à **borner l’état**.\n",
        "- La prévention des erreurs mémoire est une **conséquence** : en permettant le nettoyage des fenêtres anciennes, on évite une croissance infinie de l’état.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b15b18d1",
      "metadata": {},
      "source": [
        "%md\n",
        "\n",
        "Indiquer à Structured Streaming de conserver au maximum 2 heures de données agrégées.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e419a433",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 1471:==========================>                         (101 + 8) / 200]\r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[start: timestamp, action: string, count: bigint]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/15 16:28:52 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 9344 milliseconds\n",
            "25/12/15 16:29:01 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8595 milliseconds\n",
            "25/12/15 16:29:08 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7000 milliseconds\n",
            "[Stage 1505:============>                                        (47 + 8) / 200]\r"
          ]
        }
      ],
      "source": [
        "watermarkedDF = (inputDF\n",
        "  .withWatermark(\"time\", \"2 hours\")           # limite temporelle  de 2 heures\n",
        "  .groupBy(col(\"action\"),                     # agrège les données par action\n",
        "           window(col(\"time\"), \"1 hours\"))     # puis par des fenêtres temporelles d'une heure\n",
        "  .count()                                    # produit un décompte pour chaque agrégation\n",
        "  .select(col(\"window.start\").alias(\"start\"), # Transforme le champ en une colonne\n",
        "          col(\"action\"),                      # Inclut l'action\n",
        "          col(\"count\"))                       # Inclut le décompte\n",
        "  .orderBy(col(\"start\"), col(\"action\"))       # Trie par heure de début et par action\n",
        ")\n",
        "display(watermarkedDF)                        # Démarre le flux et l'affiche\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac33464d",
      "metadata": {},
      "source": [
        "%md\n",
        "**Commentaire :**\n",
        "* `window` est une colonne spéciale générée par l'agrégation avec window(col(\"time\"), \"2 hour\"). Elle contient des informations sur la plage temporelle de chaque fenêtre, notamment les champs start (début) et end (fin).\n",
        "* `col(\"window.start\")` accède au champ start, qui représente l'heure de début de la fenêtre temporelle.\n",
        "\n",
        "\n",
        "\n",
        "Les données reçues dans les 2 heures suivant le marquage temporel seront toujours traitées. Les données reçues 2 heures _après_ le marquage temporel peuvent ne pas être traitées. Plus les données sont retardées, moins il est probable que le moteur les traite.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af30b109",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#spark.sql(\"create database if not exists outputDelta2;\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e7a3c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ecriture du streaming dans une table Delta\n",
        "checkpointPath = \"/.../veille/stream_events/streamevent2.delta.checkpoint\"    # Sous-répertoire pour les fichiers de point de contrôle\n",
        "# Définition de la requête de streaming\n",
        "streamingQuery = (watermarkedDF                     \n",
        "  .writeStream                                    \n",
        "  .queryName(\"stream_6\")                         \n",
        "  .trigger(processingTime=\"3 seconds\")            \n",
        "  .format(\"delta\")                             \n",
        "  .option(\"checkpointLocation\", checkpointPath)  \n",
        "  .outputMode(\"complete\")                           \n",
        "  .toTable(\"outputDelta2.gold2\")                           \n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a30295",
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT * FROM outputDelta2.gold\").show(truncate=False)\n",
        "\n",
        "#spark.table(\"outputDelta2.gold\").show(truncate=False)\n",
        "#spark.sql(\"SHOW DATABASES\").show(truncate=False)\n",
        "#spark.sql(\"SHOW TABLES IN outputDelta2\").show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b05150a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " stream_3 (6a751a17-4129-41e2-af3a-173a7e8ed265)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/15 16:14:47 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 13240 milliseconds\n",
            "25/12/15 16:14:54 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7667 milliseconds\n",
            "25/12/15 16:15:02 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7820 milliseconds\n",
            "25/12/15 16:15:09 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7198 milliseconds\n",
            "25/12/15 16:15:17 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7613 milliseconds\n",
            "25/12/15 16:15:24 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6996 milliseconds\n",
            "25/12/15 16:15:32 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7739 milliseconds\n",
            "25/12/15 16:15:40 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8127 milliseconds\n",
            "25/12/15 16:15:46 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6639 milliseconds\n",
            "25/12/15 16:15:54 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7236 milliseconds\n",
            "25/12/15 16:16:02 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8297 milliseconds\n",
            "25/12/15 16:16:11 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8736 milliseconds\n",
            "25/12/15 16:16:19 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7953 milliseconds\n",
            "25/12/15 16:16:26 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6981 milliseconds\n",
            "25/12/15 16:16:32 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6794 milliseconds\n",
            "25/12/15 16:16:40 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8061 milliseconds\n",
            "25/12/15 16:16:49 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8705 milliseconds\n",
            "25/12/15 16:16:56 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6939 milliseconds\n",
            "25/12/15 16:17:06 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 10255 milliseconds\n",
            "25/12/15 16:17:14 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7485 milliseconds\n",
            "25/12/15 16:17:21 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7365 milliseconds\n",
            "25/12/15 16:17:29 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8028 milliseconds\n",
            "25/12/15 16:17:36 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7076 milliseconds\n",
            "25/12/15 16:17:44 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7336 milliseconds\n",
            "25/12/15 16:17:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6067 milliseconds\n",
            "25/12/15 16:17:57 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7108 milliseconds\n",
            "25/12/15 16:18:03 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6265 milliseconds\n",
            "25/12/15 16:18:12 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 9472 milliseconds\n",
            "25/12/15 16:18:21 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8429 milliseconds\n",
            "25/12/15 16:18:29 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7952 milliseconds\n",
            "25/12/15 16:18:36 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7442 milliseconds\n",
            "25/12/15 16:18:45 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 8868 milliseconds\n",
            "25/12/15 16:18:53 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7601 milliseconds\n",
            "25/12/15 16:18:59 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6565 milliseconds\n",
            "25/12/15 16:19:06 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6892 milliseconds\n",
            "25/12/15 16:19:12 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6047 milliseconds\n",
            "25/12/15 16:19:18 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6201 milliseconds\n",
            "25/12/15 16:19:24 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 5938 milliseconds\n",
            "25/12/15 16:19:31 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6164 milliseconds\n",
            "25/12/15 16:19:38 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7414 milliseconds\n",
            "25/12/15 16:19:44 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6372 milliseconds\n",
            "25/12/15 16:19:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6015 milliseconds\n",
            "25/12/15 16:19:56 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6072 milliseconds\n",
            "25/12/15 16:20:02 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 5912 milliseconds\n",
            "25/12/15 16:20:08 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 5901 milliseconds\n",
            "25/12/15 16:20:14 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 5750 milliseconds\n",
            "25/12/15 16:20:22 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7906 milliseconds\n",
            "25/12/15 16:20:29 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6885 milliseconds\n",
            "25/12/15 16:20:35 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6050 milliseconds\n",
            "25/12/15 16:20:43 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7629 milliseconds\n",
            "25/12/15 16:20:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7132 milliseconds\n",
            "25/12/15 16:20:55 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 5846 milliseconds\n",
            "25/12/15 16:21:01 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 5677 milliseconds\n",
            "25/12/15 16:21:07 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 5934 milliseconds\n",
            "25/12/15 16:21:13 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6127 milliseconds\n",
            "25/12/15 16:21:19 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 5851 milliseconds\n",
            "25/12/15 16:21:25 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6235 milliseconds\n",
            "25/12/15 16:21:32 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6375 milliseconds\n",
            "25/12/15 16:21:38 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6364 milliseconds\n",
            "25/12/15 16:21:45 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 6938 milliseconds\n",
            "25/12/15 16:21:52 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7287 milliseconds\n",
            "25/12/15 16:22:00 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7381 milliseconds\n",
            "25/12/15 16:22:07 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7433 milliseconds\n",
            "25/12/15 16:22:14 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7211 milliseconds\n",
            "25/12/15 16:22:22 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000} milliseconds, but spent 7502 milliseconds\n",
            "[Stage 822:===============>                                      (56 + 8) / 200]\r"
          ]
        }
      ],
      "source": [
        "# Liste flux actifs\n",
        "for stream in spark.streams.active:      # Loop over all active streams\n",
        "    print(\" {} ({})\".format(stream.name, stream.id))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e3a6a08e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/15 16:31:02 ERROR DeltaFileFormatWriter: Aborting job b5953db9-0742-44a4-8295-0f9e6f91786d\n",
            "java.lang.InterruptedException\n",
            "\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1048)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait0(Promise.scala:243)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:255)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:104)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:374)\n",
            "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:998)\n",
            "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n",
            "\tat org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.$anonfun$executeWrite$1(DeltaFileFormatWriter.scala:269)\n",
            "\tat org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.writeAndCommit(DeltaFileFormatWriter.scala:302)\n",
            "\tat org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.executeWrite(DeltaFileFormatWriter.scala:238)\n",
            "\tat org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.write(DeltaFileFormatWriter.scala:218)\n",
            "\tat org.apache.spark.sql.delta.files.TransactionalWrite.$anonfun$writeFiles$2(TransactionalWrite.scala:470)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\n",
            "\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\n",
            "\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\n",
            "\tat org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles(TransactionalWrite.scala:428)\n",
            "\tat org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles$(TransactionalWrite.scala:386)\n",
            "\tat org.apache.spark.sql.delta.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:169)\n",
            "\tat org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles(TransactionalWrite.scala:250)\n",
            "\tat org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles$(TransactionalWrite.scala:246)\n",
            "\tat org.apache.spark.sql.delta.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:169)\n",
            "\tat org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles(TransactionalWrite.scala:239)\n",
            "\tat org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles$(TransactionalWrite.scala:236)\n",
            "\tat org.apache.spark.sql.delta.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:169)\n",
            "\tat org.apache.spark.sql.delta.sources.DeltaSink.$anonfun$addBatchWithStatusImpl$4(DeltaSink.scala:152)\n",
            "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:481)\n",
            "\tat org.apache.spark.sql.delta.sources.DeltaSink.addBatchWithStatusImpl(DeltaSink.scala:152)\n",
            "\tat org.apache.spark.sql.delta.sources.DeltaSink.addBatch(DeltaSink.scala:105)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:879)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\n",
            "\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\n",
            "\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:876)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressContext.reportTimeTaken(ProgressReporter.scala:186)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:876)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$executeOneBatch$2(MicroBatchExecution.scala:394)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressContext.reportTimeTaken(ProgressReporter.scala:186)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.executeOneBatch(MicroBatchExecution.scala:364)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:344)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1$adapted(MicroBatchExecution.scala:344)\n",
            "\tat org.apache.spark.sql.execution.streaming.TriggerExecutor.runOneBatch(TriggerExecutor.scala:39)\n",
            "\tat org.apache.spark.sql.execution.streaming.TriggerExecutor.runOneBatch$(TriggerExecutor.scala:37)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.runOneBatch(TriggerExecutor.scala:70)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:82)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:344)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:337)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:311)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:226)\n",
            "25/12/15 16:31:02 WARN Shell: Interrupted while joining on: Thread[Thread-560144,5,main]\n",
            "java.lang.InterruptedException\n",
            "\tat java.base/java.lang.Object.wait(Native Method)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1313)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1381)\n",
            "\tat org.apache.hadoop.util.Shell.joinThread(Shell.java:1103)\n",
            "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:1063)\n",
            "\tat org.apache.hadoop.util.Shell.run(Shell.java:959)\n",
            "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1282)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1377)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1359)\n",
            "\tat org.apache.hadoop.fs.FileUtil.readLink(FileUtil.java:225)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal(RawLocalFileSystem.java:1251)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1240)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatus(RawLocalFileSystem.java:1211)\n",
            "\tat org.apache.hadoop.fs.DelegateToFileSystem.getFileLinkStatus(DelegateToFileSystem.java:138)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:853)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.ChecksumFs.renameInternal(ChecksumFs.java:519)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.FileContext.rename(FileContext.java:1044)\n",
            "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.renameTempFile(CheckpointFileManager.scala:376)\n",
            "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:156)\n",
            "\tat net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:198)\n",
            "\tat java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:188)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:598)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:447)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:174)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:744)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
            "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:481)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:671)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:744)\n",
            "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
            "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n",
            "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
            "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
            "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
            "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n",
            "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
            "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
            "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
            "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/15 16:31:02 WARN DAGScheduler: Failed to cancel job group e08fe081-6f45-48ec-8de2-cd67d8b6e3e1. Cannot find active jobs for it.\n",
            "25/12/15 16:31:02 WARN Shell: Interrupted while joining on: Thread[Thread-560151,5,]\n",
            "java.lang.InterruptedException\n",
            "\tat java.base/java.lang.Object.wait(Native Method)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1313)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1381)\n",
            "\tat org.apache.hadoop.util.Shell.joinThread(Shell.java:1103)\n",
            "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:1063)\n",
            "\tat org.apache.hadoop.util.Shell.run(Shell.java:959)\n",
            "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1282)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1377)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1359)\n",
            "\tat org.apache.hadoop.fs.FileUtil.readLink(FileUtil.java:225)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal(RawLocalFileSystem.java:1251)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1240)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatus(RawLocalFileSystem.java:1211)\n",
            "\tat org.apache.hadoop.fs.DelegateToFileSystem.getFileLinkStatus(DelegateToFileSystem.java:138)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:857)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.ChecksumFs.renameInternal(ChecksumFs.java:519)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.FileContext.rename(FileContext.java:1044)\n",
            "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.renameTempFile(CheckpointFileManager.scala:376)\n",
            "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:156)\n",
            "\tat net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:198)\n",
            "\tat java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:188)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:598)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:447)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:174)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:744)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
            "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:481)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:671)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:744)\n",
            "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
            "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n",
            "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
            "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
            "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
            "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n",
            "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
            "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
            "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
            "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/15 16:31:02 WARN Shell: Interrupted while joining on: Thread[Thread-560147,5,main]\n",
            "java.lang.InterruptedException\n",
            "\tat java.base/java.lang.Object.wait(Native Method)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1313)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1381)\n",
            "\tat org.apache.hadoop.util.Shell.joinThread(Shell.java:1103)\n",
            "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:1063)\n",
            "\tat org.apache.hadoop.util.Shell.run(Shell.java:959)\n",
            "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1282)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1377)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1359)\n",
            "\tat org.apache.hadoop.fs.FileUtil.readLink(FileUtil.java:225)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal(RawLocalFileSystem.java:1251)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1240)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatus(RawLocalFileSystem.java:1211)\n",
            "\tat org.apache.hadoop.fs.DelegateToFileSystem.getFileLinkStatus(DelegateToFileSystem.java:138)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:857)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.ChecksumFs.renameInternal(ChecksumFs.java:519)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.FileContext.rename(FileContext.java:1044)\n",
            "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.renameTempFile(CheckpointFileManager.scala:376)\n",
            "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:156)\n",
            "\tat net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:198)\n",
            "\tat java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:188)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:598)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:447)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:174)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:744)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
            "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:481)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:671)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:744)\n",
            "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
            "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n",
            "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
            "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
            "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
            "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n",
            "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
            "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
            "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
            "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/15 16:31:02 WARN Shell: Interrupted while joining on: Thread[Thread-560148,5,main]\n",
            "java.lang.InterruptedException\n",
            "\tat java.base/java.lang.Object.wait(Native Method)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1313)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1381)\n",
            "\tat org.apache.hadoop.util.Shell.joinThread(Shell.java:1103)\n",
            "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:1063)\n",
            "\tat org.apache.hadoop.util.Shell.run(Shell.java:959)\n",
            "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1282)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1377)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1359)\n",
            "\tat org.apache.hadoop.fs.FileUtil.readLink(FileUtil.java:225)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal(RawLocalFileSystem.java:1251)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1240)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatus(RawLocalFileSystem.java:1211)\n",
            "\tat org.apache.hadoop.fs.DelegateToFileSystem.getFileLinkStatus(DelegateToFileSystem.java:138)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:857)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.ChecksumFs.renameInternal(ChecksumFs.java:519)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.FileContext.rename(FileContext.java:1044)\n",
            "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.renameTempFile(CheckpointFileManager.scala:376)\n",
            "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:156)\n",
            "\tat net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:198)\n",
            "\tat java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:188)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:598)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:447)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:174)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:744)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
            "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:481)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:671)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:744)\n",
            "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
            "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n",
            "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
            "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
            "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
            "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n",
            "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
            "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
            "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
            "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/12/15 16:31:02 WARN Shell: Interrupted while joining on: Thread[Thread-560154,5,]\n",
            "java.lang.InterruptedException\n",
            "\tat java.base/java.lang.Object.wait(Native Method)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1313)\n",
            "\tat java.base/java.lang.Thread.join(Thread.java:1381)\n",
            "\tat org.apache.hadoop.util.Shell.joinThread(Shell.java:1103)\n",
            "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:1063)\n",
            "\tat org.apache.hadoop.util.Shell.run(Shell.java:959)\n",
            "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1282)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1377)\n",
            "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1359)\n",
            "\tat org.apache.hadoop.fs.FileUtil.readLink(FileUtil.java:225)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal(RawLocalFileSystem.java:1251)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1240)\n",
            "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatus(RawLocalFileSystem.java:1211)\n",
            "\tat org.apache.hadoop.fs.DelegateToFileSystem.getFileLinkStatus(DelegateToFileSystem.java:138)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:853)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.ChecksumFs.renameInternal(ChecksumFs.java:519)\n",
            "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:807)\n",
            "\tat org.apache.hadoop.fs.FileContext.rename(FileContext.java:1044)\n",
            "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.renameTempFile(CheckpointFileManager.scala:376)\n",
            "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:156)\n",
            "\tat net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:198)\n",
            "\tat java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:188)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:598)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:447)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:174)\n",
            "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:744)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
            "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:481)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:348)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:671)\n",
            "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:744)\n",
            "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
            "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
            "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n",
            "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
            "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
            "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
            "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n",
            "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
            "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
            "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
            "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
            "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
            "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
            "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
            "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "25/12/15 16:31:02 WARN TaskSetManager: Lost task 113.0 in stage 1687.0 (TID 76889) (win-spntmihpln0 executor driver): TaskKilled (Stage cancelled: [SPARK_JOB_CANCELLED] Job 699 cancelled Query stream_3 [id = 6a751a17-4129-41e2-af3a-173a7e8ed265, runId = e08fe081-6f45-48ec-8de2-cd67d8b6e3e1] was stopped SQLSTATE: XXKDA)\n",
            "25/12/15 16:31:02 WARN TaskSetManager: Lost task 119.0 in stage 1687.0 (TID 76895) (win-spntmihpln0 executor driver): TaskKilled (Stage cancelled: [SPARK_JOB_CANCELLED] Job 699 cancelled Query stream_3 [id = 6a751a17-4129-41e2-af3a-173a7e8ed265, runId = e08fe081-6f45-48ec-8de2-cd67d8b6e3e1] was stopped SQLSTATE: XXKDA)\n",
            "25/12/15 16:31:02 WARN TaskSetManager: Lost task 114.0 in stage 1687.0 (TID 76890) (win-spntmihpln0 executor driver): TaskKilled (Stage cancelled: [SPARK_JOB_CANCELLED] Job 699 cancelled Query stream_3 [id = 6a751a17-4129-41e2-af3a-173a7e8ed265, runId = e08fe081-6f45-48ec-8de2-cd67d8b6e3e1] was stopped SQLSTATE: XXKDA)\n",
            "25/12/15 16:31:02 WARN TaskSetManager: Lost task 117.0 in stage 1687.0 (TID 76893) (win-spntmihpln0 executor driver): TaskKilled (Stage cancelled: [SPARK_JOB_CANCELLED] Job 699 cancelled Query stream_3 [id = 6a751a17-4129-41e2-af3a-173a7e8ed265, runId = e08fe081-6f45-48ec-8de2-cd67d8b6e3e1] was stopped SQLSTATE: XXKDA)\n",
            "25/12/15 16:31:02 WARN TaskSetManager: Lost task 112.0 in stage 1687.0 (TID 76888) (win-spntmihpln0 executor driver): TaskKilled (Stage cancelled: [SPARK_JOB_CANCELLED] Job 699 cancelled Query stream_3 [id = 6a751a17-4129-41e2-af3a-173a7e8ed265, runId = e08fe081-6f45-48ec-8de2-cd67d8b6e3e1] was stopped SQLSTATE: XXKDA)\n",
            "25/12/15 16:31:02 WARN TaskSetManager: Lost task 116.0 in stage 1687.0 (TID 76892) (win-spntmihpln0 executor driver): TaskKilled (Stage cancelled: [SPARK_JOB_CANCELLED] Job 699 cancelled Query stream_3 [id = 6a751a17-4129-41e2-af3a-173a7e8ed265, runId = e08fe081-6f45-48ec-8de2-cd67d8b6e3e1] was stopped SQLSTATE: XXKDA)\n",
            "25/12/15 16:31:02 WARN TaskSetManager: Lost task 115.0 in stage 1687.0 (TID 76891) (win-spntmihpln0 executor driver): TaskKilled (Stage cancelled: [SPARK_JOB_CANCELLED] Job 699 cancelled Query stream_3 [id = 6a751a17-4129-41e2-af3a-173a7e8ed265, runId = e08fe081-6f45-48ec-8de2-cd67d8b6e3e1] was stopped SQLSTATE: XXKDA)\n",
            "25/12/15 16:31:02 WARN TaskSetManager: Lost task 118.0 in stage 1687.0 (TID 76894) (win-spntmihpln0 executor driver): TaskKilled (Stage cancelled: [SPARK_JOB_CANCELLED] Job 699 cancelled Query stream_3 [id = 6a751a17-4129-41e2-af3a-173a7e8ed265, runId = e08fe081-6f45-48ec-8de2-cd67d8b6e3e1] was stopped SQLSTATE: XXKDA)\n"
          ]
        }
      ],
      "source": [
        "# Arrêter tous les flux\n",
        "for s in spark.streams.active: \n",
        "  s.stop()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "smarttech-streaming",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
